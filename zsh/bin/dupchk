#!/usr/bin/env zsh
# dupsize.zsh â€” list duplicate-size files and optionally resolve them interactively.

set -o pipefail
set -o noclobber
set -o errexit
set -o nounset

autoload -Uz colors && colors
c()    { print -P -- "%F{$1}$2%f"; }
info() { c blue "$1"; }
ok()   { c green "$1"; }
warn() { c yellow "$1"; }
err()  { c red "$1" >&2; }

use_group=false
use_interactive=false
srcdir="."

usage() {
  cat <<'USAGE'
dupsize.zsh [-g] [-i] [directory]

  -g   Group by size with headers
  -i   Interactive resolver (fzf to keep one, trash the rest)

Duplicates are detected by file size only (fast heuristic).
USAGE
}

# ---- Parse args ----
zmodload zsh/zutil
zparseopts -D -E -F -- g=opt_g i=opt_i h=opt_h -help=opt_h || { err "bad flags"; usage; exit 2; }
(( ${#opt_h} )) && { usage; exit 0; }
(( ${#opt_g} )) && use_group=true
(( ${#opt_i} )) && use_interactive=true
[[ $# -gt 0 ]] && srcdir=$1
[[ -d $srcdir ]] || { err "Not a directory: $srcdir"; exit 1; }

# ---- Gather data (same as original) ----
data="$(
  fd . "$srcdir" --exact-depth 1 -t f -0 \
    | xargs -0 stat -f $'%z\t%N' 2>/dev/null \
    | sort -n
)" || true

[[ -z $data ]] && { ok "No files found."; exit 0; }

# ---- Group parser (AWK, same logic as original) ----
print_grouped() {
  awk -F '\t' '
    {
      size=$1; name=$2; gsub(/^\"|\"$/, "", name)
      if (size==prev) {
        if (!opened) { printf("\n# %s bytes\n", prev); print first; opened=1 }
        print name
      } else {
        prev=size; first=name; opened=0
      }
    }
  ' <<< "$data"
}

print_flat() {
  awk -F '\t' '
    {
      size=$1; name=$2; gsub(/^\"|\"$/, "", name)
      if (size==prev) {
        if (!printed_first) { print first; printed_first=1 }
        print name
      } else {
        prev=size; first=name; printed_first=0
      }
    }
  ' <<< "$data"
}

# ---- Safe trash ----
safe_trash() {
  local f="$1"
  if command -v trash >/dev/null 2>&1; then
    trash -- "$f"
  else
    local dst="$HOME/.Trash/${f:t}"
    local base="${f:t}" ts n=1
    ts=$(date +%Y%m%d-%H%M%S)
    while [[ -e $dst ]]; do
      dst="$HOME/.Trash/${base} (${ts}-${n})"
      n=$((n+1))
    done
    mv -n -- "$f" "$dst"
  fi
}

# ---- Interactive resolver ----
interactive_resolve() {
  command -v fzf >/dev/null 2>&1 || { err "fzf required for -i"; exit 127; }

  # Group by size first
  local sizes=()
  sizes=($(awk '{print $1}' <<< "$data" | uniq -d))

  for s in $sizes; do
    local group keep to_trash=()
    group=$(awk -F '\t' -v sz=$s '$1==sz { gsub(/^\"|\"$/, "", $2); print $2 }' <<< "$data")
    [[ -z $group ]] && continue

    print -- "$(warn "Duplicate-size group: $s bytes")"
    keep=$(print -r -- "$group" | fzf --prompt="keep> " --header="Select file to keep ($s bytes)" --no-multi)
    [[ -z $keep ]] && { warn "Skipped group."; continue; }

    while IFS= read -r f; do
      [[ $f == "$keep" ]] && continue
      to_trash+=("$f")
    done <<< "$group"

    [[ ${#to_trash[@]} -eq 0 ]] && continue
    print -- "$(info "Keep: $keep")"
    print -- "$(warn "Trash ${#to_trash[@]} file(s)?")"
    printf '%s\n' "${to_trash[@]}"

    printf "%s " "$(warn '[y/N]')"
    read -r ans
    case $ans in
      y|Y|yes|YES)
        for f in "${to_trash[@]}"; do safe_trash "$f"; done
        ok "Trashed ${#to_trash[@]} file(s)."
        ;;
      *) warn "Skipped." ;;
    esac
  done
}

# ---- Run ----
if $use_interactive; then
  interactive_resolve
else
  if $use_group; then
    print_grouped
  else
    print_flat
  fi
fi
